{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes Data Preprocessing - Complete 5 Phase Pipeline\n",
    "\n",
    "# ==================== IMPORTS & SETUP ====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import warnings\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "\n",
    "# ==================== FILE HANDLING ====================\n",
    "\n",
    "def find_and_load_dataset():\n",
    "    \"\"\"Find and load the diabetes dataset with multiple fallback options\"\"\"\n",
    "    \n",
    "    # Possible file names and paths\n",
    "    possible_paths = [\n",
    "        'diabetes.csv',\n",
    "        'Diabetes Missing Data.csv',\n",
    "        '../diabetes.csv', \n",
    "        '../Diabetes Missing Data.csv',\n",
    "        './diabetes.csv',\n",
    "        './Diabetes Missing Data.csv',\n",
    "        'data/diabetes.csv',\n",
    "        '../data/diabetes.csv'\n",
    "    ]\n",
    "    \n",
    "    # Check each possible path\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            df = pd.read_csv(path)\n",
    "            print(f\"‚úÖ Dataset found at: {path}\")\n",
    "            \n",
    "            # Check and rename columns to standard format\n",
    "            column_mapping = {}\n",
    "            if 'BloodPressure' not in df.columns and 'Diastolic_BP' in df.columns:\n",
    "                column_mapping['Diastolic_BP'] = 'BloodPressure'\n",
    "            if 'SkinThickness' not in df.columns and 'Skin_Fold' in df.columns:\n",
    "                column_mapping['Skin_Fold'] = 'SkinThickness'\n",
    "            if 'Insulin' not in df.columns and 'Serum_Insulin' in df.columns:\n",
    "                column_mapping['Serum_Insulin'] = 'Insulin'\n",
    "            if 'DiabetesPedigreeFunction' not in df.columns and 'Diabetes_Pedigree' in df.columns:\n",
    "                column_mapping['Diabetes_Pedigree'] = 'DiabetesPedigreeFunction'\n",
    "            if 'Outcome' not in df.columns and 'Class' in df.columns:\n",
    "                column_mapping['Class'] = 'Outcome'\n",
    "            \n",
    "            if column_mapping:\n",
    "                df = df.rename(columns=column_mapping)\n",
    "                print(f\"‚úÖ Renamed columns: {column_mapping}\")\n",
    "            \n",
    "            return df, path\n",
    "    \n",
    "    # If no local file found, download from web\n",
    "    print(\" No local file found. Downloading from web...\")\n",
    "    try:\n",
    "        url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "        column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', \n",
    "                       'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        df = pd.read_csv(io.StringIO(response.text), names=column_names)\n",
    "        \n",
    "        # Save for future use\n",
    "        df.to_csv('diabetes.csv', index=False)\n",
    "        print(\" Dataset downloaded and saved as 'diabetes.csv'\")\n",
    "        return df, 'diabetes.csv'\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Download failed: {e}\")\n",
    "        print(\" Creating sample dataset for demonstration...\")\n",
    "        \n",
    "        # Create sample data\n",
    "        np.random.seed(42)\n",
    "        n_samples = 768\n",
    "        \n",
    "        data = {\n",
    "            'Pregnancies': np.random.randint(0, 15, n_samples),\n",
    "            'Glucose': np.random.randint(50, 200, n_samples),\n",
    "            'BloodPressure': np.random.randint(50, 110, n_samples),\n",
    "            'SkinThickness': np.random.randint(10, 50, n_samples),\n",
    "            'Insulin': np.random.randint(0, 200, n_samples),\n",
    "            'BMI': np.random.uniform(20, 45, n_samples),\n",
    "            'DiabetesPedigreeFunction': np.random.uniform(0.1, 2.5, n_samples),\n",
    "            'Age': np.random.randint(20, 70, n_samples),\n",
    "            'Outcome': np.random.randint(0, 2, n_samples)\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv('diabetes.csv', index=False)\n",
    "        print(\"‚úÖ Sample dataset created and saved as 'diabetes.csv'\")\n",
    "        return df, 'diabetes.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df, file_path = find_and_load_dataset()\n",
    "print(f\"üìä Dataset shape: {df.shape}\")\n",
    "print(f\"üìù Actual columns: {df.columns.tolist()}\")\n",
    "\n",
    "# ==================== PHASE 1: DATA COLLECTION & UNDERSTANDING ====================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE 1: DATA COLLECTION & UNDERSTANDING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "print(f\" Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Display basic information\n",
    "print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "print(\" DATASET INFORMATION\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "df.info()\n",
    "\n",
    "# Basic Statistics\n",
    "print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "print(\" BASIC STATISTICS\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "print(df.describe())\n",
    "\n",
    "# First few rows\n",
    "print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "print(\" FIRST 5 ROWS\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "print(df.head())\n",
    "\n",
    "# Data Quality Assessment\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\" DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Biological features where zero is impossible - check which ones exist\n",
    "biological_features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "available_bio_features = [feature for feature in biological_features if feature in df.columns]\n",
    "\n",
    "print(\" Zeros in Biological Features (Potential Missing Values):\")\n",
    "zero_summary = {}\n",
    "for feature in available_bio_features:\n",
    "    zero_count = (df[feature] == 0).sum()\n",
    "    percentage = (zero_count / len(df)) * 100\n",
    "    zero_summary[feature] = zero_count\n",
    "    print(f\"   üî∏ {feature}: {zero_count} zeros ({percentage:.2f}%)\")\n",
    "\n",
    "# Check class distribution - find target column\n",
    "target_col = None\n",
    "for possible_target in ['Outcome', 'Class']:\n",
    "    if possible_target in df.columns:\n",
    "        target_col = possible_target\n",
    "        break\n",
    "\n",
    "if target_col:\n",
    "    print(f\"\\n Target Variable Distribution ({target_col}):\")\n",
    "    class_dist = df[target_col].value_counts()\n",
    "    print(class_dist)\n",
    "    if len(class_dist) > 1:\n",
    "        imbalance_ratio = class_dist[0] / class_dist[1]\n",
    "        print(f\" Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "    else:\n",
    "        print(\" Only one class found in target variable\")\n",
    "else:\n",
    "    print(\" No target variable found in dataset\")\n",
    "\n",
    "# Visualize class distribution if target exists\n",
    "if target_col:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.countplot(data=df, x=target_col, palette=['skyblue', 'salmon'])\n",
    "    plt.title(f'Class Distribution\\n(0 = Non-diabetic, 1 = Diabetic)')\n",
    "    plt.xlabel(target_col)\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.pie(class_dist, labels=['Non-diabetic', 'Diabetic'], autopct='%1.1f%%', \n",
    "            colors=['lightblue', 'lightcoral'], startangle=90)\n",
    "    plt.title('Class Distribution (%)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\n Duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\" Data types are consistent: {all(df.dtypes != 'object')}\")\n",
    "print(\"\\n PHASE 1 COMPLETED - Ready for Data Cleaning!\")\n",
    "\n",
    "# ==================== PHASE 2: DATA CLEANING ====================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PHASE 2: DATA CLEANING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df_cleaned = df.copy()\n",
    "print(\" Created working copy of the dataset\")\n",
    "\n",
    "# 1. Handle Missing Values\n",
    "print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "print(\"1. üõ†Ô∏è HANDLING MISSING VALUES\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "\n",
    "print(\" Replacing impossible zeros with NaN...\")\n",
    "for feature in available_bio_features:\n",
    "    zero_count = (df_cleaned[feature] == 0).sum()\n",
    "    if zero_count > 0:\n",
    "        df_cleaned[feature] = df_cleaned[feature].replace(0, np.nan)\n",
    "        print(f\"   ‚úÖ {feature}: {zero_count} zeros replaced with NaN\")\n",
    "\n",
    "# Check missing values after replacement\n",
    "print(\"\\n Missing values after zero replacement:\")\n",
    "missing_after = df_cleaned.isnull().sum()\n",
    "print(missing_after[missing_after > 0])\n",
    "\n",
    "# Visualize missing values\n",
    "plt.figure(figsize=(12, 6))\n",
    "msno.matrix(df_cleaned)\n",
    "plt.title('Missing Values Pattern After Zero Replacement')\n",
    "plt.show()\n",
    "\n",
    "# Apply imputation strategy\n",
    "print(\"\\nüîß Applying imputation strategy...\")\n",
    "\n",
    "# For glucose, blood pressure, BMI - use median\n",
    "median_features = ['Glucose', 'BloodPressure', 'BMI']\n",
    "for feature in median_features:\n",
    "    if feature in df_cleaned.columns:\n",
    "        median_val = df_cleaned[feature].median()\n",
    "        df_cleaned[feature].fillna(median_val, inplace=True)\n",
    "        print(f\"    {feature}: Imputed with median ({median_val:.2f})\")\n",
    "\n",
    "# For skin thickness and insulin - use KNN imputer\n",
    "knn_features = ['SkinThickness', 'Insulin']\n",
    "available_knn = [feature for feature in knn_features if feature in df_cleaned.columns]\n",
    "\n",
    "if available_knn:\n",
    "    knn_imputer = KNNImputer(n_neighbors=5)\n",
    "    df_cleaned[available_knn] = knn_imputer.fit_transform(df_cleaned[available_knn])\n",
    "    print(f\"    {available_knn}: Imputed using KNN\")\n",
    "\n",
    "# 2. Handle Outliers\n",
    "print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "print(\"2. üìè HANDLING OUTLIERS\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "\n",
    "print(\" Detecting and treating outliers using IQR method...\")\n",
    "numerical_features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', \n",
    "                     'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "available_numerical = [feature for feature in numerical_features if feature in df_cleaned.columns]\n",
    "\n",
    "outlier_count = 0\n",
    "for feature in available_numerical:\n",
    "    Q1 = df_cleaned[feature].quantile(0.25)\n",
    "    Q3 = df_cleaned[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Count outliers before treatment\n",
    "    outliers_before = ((df_cleaned[feature] < lower_bound) | (df_cleaned[feature] > upper_bound)).sum()\n",
    "    outlier_count += outliers_before\n",
    "    \n",
    "    # Cap outliers\n",
    "    df_cleaned[feature] = np.clip(df_cleaned[feature], lower_bound, upper_bound)\n",
    "\n",
    "print(f\"‚úÖ Treated {outlier_count} outliers using IQR capping method\")\n",
    "\n",
    "# Show outlier treatment comparison\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(['Glucose', 'BMI', 'Insulin'][:3], 1):\n",
    "    if feature in df_cleaned.columns:\n",
    "        plt.subplot(2, 3, i)\n",
    "        plt.hist(df[feature], bins=30, alpha=0.7, color='blue', label='Original')\n",
    "        plt.title(f'Original {feature}')\n",
    "        plt.xlabel(feature)\n",
    "        \n",
    "        plt.subplot(2, 3, i+3)\n",
    "        plt.hist(df_cleaned[feature], bins=30, alpha=0.7, color='green', label='Cleaned')\n",
    "        plt.title(f'Cleaned {feature}')\n",
    "        plt.xlabel(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n Cleaned dataset shape: {df_cleaned.shape}\")\n",
    "print(\"PHASE 2 COMPLETED - Data cleaned successfully!\")\n",
    "\n",
    "# ==================== PHASE 3: DATA TRANSFORMATION ====================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PHASE 3: DATA TRANSFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df_transformed = df_cleaned.copy()\n",
    "\n",
    "# 1. Feature Engineering\n",
    "print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "print(\"1. üîß FEATURE ENGINEERING\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "\n",
    "print(\" Creating new features...\")\n",
    "\n",
    "# Age groups\n",
    "if 'Age' in df_transformed.columns:\n",
    "    bins = [0, 30, 45, 60, 100]\n",
    "    labels = ['Young', 'Middle-aged', 'Senior', 'Elderly']\n",
    "    df_transformed['Age_Group'] = pd.cut(df_transformed['Age'], bins=bins, labels=labels)\n",
    "    print(\"    Created Age_Group feature\")\n",
    "\n",
    "# BMI categories\n",
    "if 'BMI' in df_transformed.columns:\n",
    "    bmi_bins = [0, 18.5, 25, 30, 100]\n",
    "    bmi_labels = ['Underweight', 'Normal', 'Overweight', 'Obese']\n",
    "    df_transformed['BMI_Category'] = pd.cut(df_transformed['BMI'], bins=bmi_bins, labels=bmi_labels)\n",
    "    print(\"    Created BMI_Category feature\")\n",
    "\n",
    "# Glucose categories\n",
    "if 'Glucose' in df_transformed.columns:\n",
    "    glucose_bins = [0, 70, 99, 125, 200, 300]\n",
    "    glucose_labels = ['Low', 'Normal', 'Prediabetic', 'Diabetic', 'High Diabetic']\n",
    "    df_transformed['Glucose_Category'] = pd.cut(df_transformed['Glucose'], bins=glucose_bins, labels=glucose_labels)\n",
    "    print(\"   Created Glucose_Category feature\")\n",
    "\n",
    "print(\" Feature engineering completed!\")\n",
    "new_features = [col for col in df_transformed.columns if col not in df_cleaned.columns]\n",
    "print(f\" New features: {new_features}\")\n",
    "\n",
    "# 2. Encoding\n",
    "print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "print(\"2.  ENCODING CATEGORICAL FEATURES\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "\n",
    "print(\" Encoding categorical features...\")\n",
    "categorical_features = ['Age_Group', 'BMI_Category', 'Glucose_Category']\n",
    "available_categorical = [feature for feature in categorical_features if feature in df_transformed.columns]\n",
    "\n",
    "for feature in available_categorical:\n",
    "    le = LabelEncoder()\n",
    "    df_transformed[f'{feature}_Encoded'] = le.fit_transform(df_transformed[feature])\n",
    "    print(f\"    Encoded {feature}\")\n",
    "\n",
    "print(\" All categorical features encoded!\")\n",
    "\n",
    "# 3. Feature Scaling\n",
    "print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "print(\"3. ‚öñÔ∏è FEATURE SCALING\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "\n",
    "print(\" Comparing StandardScaler vs MinMaxScaler...\")\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler_standard = StandardScaler()\n",
    "df_standard = df_transformed.copy()\n",
    "\n",
    "for feature in available_numerical:\n",
    "    df_standard[feature] = scaler_standard.fit_transform(df_standard[[feature]])\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "scaler_minmax = MinMaxScaler()\n",
    "df_minmax = df_transformed.copy()\n",
    "\n",
    "for feature in available_numerical:\n",
    "    df_minmax[feature] = scaler_minmax.fit_transform(df_minmax[[feature]])\n",
    "\n",
    "print(\" Both scaling methods applied for comparison\")\n",
    "\n",
    "# Show scaling comparison\n",
    "if 'Glucose' in df_transformed.columns:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.hist(df_transformed['Glucose'], bins=30, alpha=0.7, color='blue')\n",
    "    plt.title('Original Glucose')\n",
    "    plt.xlabel('Glucose')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.hist(df_standard['Glucose'], bins=30, alpha=0.7, color='green')\n",
    "    plt.title('StandardScaler Glucose')\n",
    "    plt.xlabel('Glucose')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.hist(df_minmax['Glucose'], bins=30, alpha=0.7, color='red')\n",
    "    plt.title('MinMaxScaler Glucose')\n",
    "    plt.xlabel('Glucose')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Choose StandardScaler (better for algorithms assuming normal distribution)\n",
    "df_transformed = df_standard\n",
    "print(\"\\n Selected StandardScaler for final dataset\")\n",
    "\n",
    "print(f\"\\n Transformed dataset shape: {df_transformed.shape}\")\n",
    "print(\"PHASE 3 COMPLETED - Data transformed successfully!\")\n",
    "\n",
    "# ==================== PHASE 4: DATA REDUCTION ====================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PHASE 4: DATA REDUCTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Feature Selection\n",
    "print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "print(\"1. üîç FEATURE SELECTION\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "\n",
    "# Prepare features and target\n",
    "feature_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', \n",
    "                 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age',\n",
    "                 'Age_Group_Encoded', 'BMI_Category_Encoded', 'Glucose_Category_Encoded']\n",
    "available_features = [col for col in feature_columns if col in df_transformed.columns]\n",
    "\n",
    "X = df_transformed[available_features]\n",
    "y = df_transformed[target_col] if target_col else None\n",
    "\n",
    "if y is not None:\n",
    "    # Feature selection using mutual information\n",
    "    selector = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "    # Feature importance scores\n",
    "    feature_scores = pd.DataFrame({\n",
    "        'Feature': available_features,\n",
    "        'Score': selector.scores_\n",
    "    }).sort_values('Score', ascending=False)\n",
    "\n",
    "    print(\" Feature Importance Scores:\")\n",
    "    print(feature_scores)\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_scores, x='Score', y='Feature', palette='viridis')\n",
    "    plt.title('Feature Importance Scores (Mutual Information)')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Select top 6 features\n",
    "    top_features = feature_scores.head(6)['Feature'].tolist()\n",
    "    print(f\"\\nüéØ Selected top 6 features: {top_features}\")\n",
    "\n",
    "    # 2. Dimensionality Reduction\n",
    "    print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "    print(\"2.  DIMENSIONALITY REDUCTION (PCA)\")\n",
    "    print(\"‚îÄ\" * 50)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X_selected)\n",
    "\n",
    "    # Plot explained variance\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.ylabel('Explained Variance Ratio')\n",
    "    plt.title('Individual Explained Variance')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "             np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.title('Cumulative Explained Variance')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\" Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "    print(\" Cumulative explained variance:\", np.cumsum(pca.explained_variance_ratio_))\n",
    "\n",
    "    # Find optimal number of components\n",
    "    n_components = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1\n",
    "    print(f\"\\nüéØ Recommended number of components: {n_components} (95% variance explained)\")\n",
    "\n",
    "    # Create reduced dataset\n",
    "    pca_reduced = PCA(n_components=n_components)\n",
    "    X_reduced = pca_reduced.fit_transform(X_selected)\n",
    "    \n",
    "    # Create DataFrame with reduced features\n",
    "    reduced_columns = [f'PC{i+1}' for i in range(n_components)]\n",
    "    df_reduced = pd.DataFrame(X_reduced, columns=reduced_columns)\n",
    "    df_reduced[target_col] = y.values\n",
    "    \n",
    "    print(f\"\\n Reduced dataset shape: {df_reduced.shape}\")\n",
    "    print(\" PHASE 4 COMPLETED - Data reduced successfully!\")\n",
    "else:\n",
    "    print(\" Cannot perform feature selection without target variable\")\n",
    "    df_reduced = df_transformed\n",
    "\n",
    "# ==================== PHASE 5: DATA IMBALANCE HANDLING ====================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PHASE 5: DATA IMBALANCE HANDLING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if target_col and y is not None:\n",
    "    # 1. Class Distribution Analysis\n",
    "    print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "    print(\"1.  CLASS DISTRIBUTION ANALYSIS\")\n",
    "    print(\"‚îÄ\" * 50)\n",
    "\n",
    "    print(\"Original class distribution:\")\n",
    "    original_dist = df_transformed[target_col].value_counts()\n",
    "    print(original_dist)\n",
    "\n",
    "    imbalance_ratio = original_dist[0] / original_dist[1]\n",
    "    print(f\" Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "    # Visualize original distribution\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.countplot(data=df_transformed, x=target_col, palette=['skyblue', 'salmon'])\n",
    "    plt.title('Original Class Distribution')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.pie(original_dist, labels=['Non-diabetic', 'Diabetic'], autopct='%1.1f%%', \n",
    "            colors=['lightblue', 'lightcoral'], startangle=90)\n",
    "    plt.title('Original Class Distribution (%)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Balancing Techniques\n",
    "    print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "    print(\"2. ‚öñÔ∏è APPLYING SMOTE FOR CLASS BALANCING\")\n",
    "    print(\"‚îÄ\" * 50)\n",
    "\n",
    "    print(\" Applying SMOTE (Synthetic Minority Over-sampling Technique)...\")\n",
    "\n",
    "    # Prepare features for balancing\n",
    "    if 'df_reduced' in locals() and hasattr(df_reduced, 'shape'):\n",
    "        X_balance = df_reduced.drop(columns=[target_col])\n",
    "    else:\n",
    "        X_balance = df_transformed[available_features]\n",
    "        \n",
    "    y_balance = df_transformed[target_col]\n",
    "\n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_balanced, y_balanced = smote.fit_resample(X_balance, y_balance)\n",
    "\n",
    "    print(\" SMOTE applied successfully!\")\n",
    "\n",
    "    # Create balanced dataset\n",
    "    df_balanced = pd.DataFrame(X_balanced, columns=X_balance.columns)\n",
    "    df_balanced[target_col] = y_balanced\n",
    "\n",
    "    print(\"\\nBalanced class distribution:\")\n",
    "    balanced_dist = df_balanced[target_col].value_counts()\n",
    "    print(balanced_dist)\n",
    "\n",
    "    # Visualize balanced distribution\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.countplot(data=df_balanced, x=target_col, palette=['lightgreen', 'lightcoral'])\n",
    "    plt.title('Balanced Class Distribution (After SMOTE)')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.pie(balanced_dist, labels=['Non-diabetic', 'Diabetic'], autopct='%1.1f%%', \n",
    "            colors=['lightgreen', 'lightcoral'], startangle=90)\n",
    "    plt.title('Balanced Class Distribution (%)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\n Balanced dataset shape: {df_balanced.shape}\")\n",
    "    print(\" PHASE 5 COMPLETED - Class imbalance handled successfully!\")\n",
    "else:\n",
    "    print(\" Cannot perform imbalance handling without target variable\")\n",
    "    df_balanced = df_reduced if 'df_reduced' in locals() else df_transformed\n",
    "\n",
    "# ==================== FINAL OUTPUT & SUMMARY ====================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL OUTPUT & SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save all processed datasets\n",
    "print(\" Saving processed datasets...\")\n",
    "\n",
    "df_cleaned.to_csv('diabetes_cleaned.csv', index=False)\n",
    "df_transformed.to_csv('diabetes_transformed.csv', index=False)\n",
    "\n",
    "if 'df_reduced' in locals() and hasattr(df_reduced, 'shape'):\n",
    "    df_reduced.to_csv('diabetes_reduced.csv', index=False)\n",
    "    \n",
    "if 'df_balanced' in locals() and hasattr(df_balanced, 'shape'):\n",
    "    df_balanced.to_csv('diabetes_balanced_final.csv', index=False)\n",
    "    final_df = df_balanced\n",
    "else:\n",
    "    final_df = df_transformed\n",
    "\n",
    "print(\" All datasets saved successfully!\")\n",
    "\n",
    "# Generate comprehensive summary\n",
    "print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "print(\" COMPREHENSIVE PROCESSING SUMMARY\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "\n",
    "print(\"DATASET TRANSFORMATION JOURNEY:\")\n",
    "print(f\"   Phase 1 - Original: {df.shape}\")\n",
    "print(f\"   Phase 2 - Cleaned: {df_cleaned.shape}\")\n",
    "print(f\"   Phase 3 - Transformed: {df_transformed.shape}\")\n",
    "if 'df_reduced' in locals() and hasattr(df_reduced, 'shape'):\n",
    "    print(f\"   Phase 4 - Reduced: {df_reduced.shape}\")\n",
    "if 'df_balanced' in locals() and hasattr(df_balanced, 'shape'):\n",
    "    print(f\"   Phase 5 - Balanced: {df_balanced.shape}\")\n",
    "\n",
    "if target_col:\n",
    "    print(f\"\\nTARGET VARIABLE TRANSFORMATION:\")\n",
    "    print(f\"   Original: {df[target_col].value_counts().to_dict()}\")\n",
    "    if 'df_balanced' in locals() and hasattr(df_balanced, 'shape'):\n",
    "        print(f\"   Final Balanced: {df_balanced[target_col].value_counts().to_dict()}\")\n",
    "\n",
    "print(f\"\\nFEATURES CREATED:\")\n",
    "new_features = [col for col in final_df.columns if col not in df.columns]\n",
    "for feature in new_features:\n",
    "    print(f\"   - {feature}\")\n",
    "\n",
    "print(f\"\\nDATA QUALITY IMPROVEMENTS:\")\n",
    "print(\"   ‚úÖ Missing values (zeros) identified and handled\")\n",
    "print(\"   ‚úÖ Outliers detected and treated\")\n",
    "print(\"   ‚úÖ New informative features created\")\n",
    "print(\"   ‚úÖ Features scaled for machine learning\")\n",
    "print(\"   ‚úÖ Feature selection performed\")\n",
    "print(\"   ‚úÖ Dimensionality reduction applied\")\n",
    "if target_col:\n",
    "    print(\"   ‚úÖ Class imbalance addressed with SMOTE\")\n",
    "\n",
    "# Display final dataset preview\n",
    "print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "print(\"üîç FINAL PROCESSED DATASET PREVIEW\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "\n",
    "print(\"First 5 rows of final processed data:\")\n",
    "print(final_df.head())\n",
    "\n",
    "print(\"\\nFinal dataset info:\")\n",
    "print(final_df.info())\n",
    "\n",
    "# Data Dictionary\n",
    "print(\"\\n\" + \"‚îÄ\" * 50)\n",
    "print(\" DATA DICTIONARY\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "\n",
    "data_dict = {\n",
    "    'Pregnancies': 'Number of times pregnant',\n",
    "    'Glucose': 'Plasma glucose concentration (mg/dL)',\n",
    "    'BloodPressure': 'Diastolic blood pressure (mm Hg)',\n",
    "    'SkinThickness': 'Triceps skin fold thickness (mm)',\n",
    "    'Insulin': '2-Hour serum insulin (mu U/ml)',\n",
    "    'BMI': 'Body mass index (kg/m¬≤)',\n",
    "    'DiabetesPedigreeFunction': 'Diabetes pedigree function',\n",
    "    'Age': 'Age in years',\n",
    "    'Outcome': 'Target variable (0 = non-diabetic, 1 = diabetic)',\n",
    "    'Age_Group': 'Categorical age groups (Young, Middle-aged, Senior, Elderly)',\n",
    "    'BMI_Category': 'BMI classification (Underweight, Normal, Overweight, Obese)',\n",
    "    'Glucose_Category': 'Glucose level classification'\n",
    "}\n",
    "\n",
    "for feature, description in data_dict.items():\n",
    "    if feature in final_df.columns:\n",
    "        print(f\"{feature}: {description}\")\n",
    "\n",
    "print(f\"\\n Final Dataset Ready for Machine Learning!\")\n",
    "print(f\" Output files:\")\n",
    "print(f\"   - diabetes_cleaned.csv (Phase 2 output)\")\n",
    "print(f\"   - diabetes_transformed.csv (Phase 3 output)\")\n",
    "if 'df_reduced' in locals() and hasattr(df_reduced, 'shape'):\n",
    "    print(f\"   - diabetes_reduced.csv (Phase 4 output)\")\n",
    "if 'df_balanced' in locals() and hasattr(df_balanced, 'shape'):\n",
    "    print(f\"   - diabetes_balanced_final.csv (Phase 5 output - Recommended)\")\n",
    "\n",
    "print(f\"Final shape: {final_df.shape}\")\n",
    "if target_col:\n",
    "    print(f\"Target variable: '{target_col}' (0=Non-diabetic, 1=Diabetic)\")\n",
    "\n",
    "print(\"\\n\" + \"\" * 20)\n",
    "print(\" 5-PHASE DATA PROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "print(\" \" * 20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
